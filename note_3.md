# 一、背景

## 1.1 背景1
理解程序行为是计算机架构和程序优化的基础。许多程序即使在非常大的尺度上（即在整个程序执行过程中）也表现出截然不同的行为。这一认识对许多架构和编译器技术都有影响，包括线程调度、反馈导向优化以及程序的模拟方式。然而，为了利用这种随时间变化的行为，我们首先需要开发能够自动且高效地分析程序在大段执行过程中的行为的分析工具。

程序在其运行时间内可能表现出截然不同的行为，这些行为即使在大尺度上也能观察到。理解这些大规模的程序行为可以解锁许多新的优化方法。这些优化方法包括：利用线程行为变化信息的新线程调度算法、不仅针对代码整体性能而且针对执行各个阶段进行反馈导向优化的方法，以及能够准确模拟整个程序行为的仿真技术。**为了实现这些优化，我们首先需要一个能够自动且高效地分析程序在大段执行过程中的行为的分析工具。**

## 1.2 背景2
如今，完全在详细的模拟器中执行程序已经不再可行，特别是在架构研究中。由于详细模拟需要大量的计算资源，因此只能模拟程序的一小部分。由于仅能执行程序的一小部分，确保所模拟的部分能准确代表整个程序的行为变得尤为重要。


为什么会表现不同行为：

 - **程序结构和复杂性**：
 现代程序往往非常复杂，包含大量的代码、数据结构和算法。这种复杂性使得程序的行为难以预测，尤其是在不同的输入和执行环境下。
  - **输入数据的多样性**：
   程序的输入数据可能变化很大，从简单的测试用例到复杂的大型数据集。不同的输入数据会导致程序执行路径的不同，从而表现出不同的行为。
   - **并发和并行性：**
   许多现代程序利用多线程、多进程或分布式计算来提高性能。并发和并行执行增加了程序行为的复杂性，因为线程或进程之间的交互和竞争条件可能导致不同的执行结果。
  - **硬件和操作系统的差异：**
   不同的硬件平台（如CPU、内存、存储设备）和操作系统（如Windows、Linux、macOS）具有不同的性能和特性。这些差异会影响程序的执行速度和资源使用，从而导致不同的行为表现。
   - **环境和配置的变化：**
   程序可能在不同的环境中运行，如开发环境、测试环境和生产环境。这些环境之间的差异（如配置设置、资源限制、安全策略等）可能导致程序行为的变化。
   - **随机性和不确定性：**
   某些程序包含随机元素（如随机数生成器、概率决策等），这些元素会导致程序每次运行时都表现出不同的行为。此外，系统中的不确定性（如网络延迟、硬件故障等）也可能影响程序的行为。
   - **算法和策略的选择：**
   程序中的算法和策略（如搜索算法、排序算法、调度策略等）可能具有不同的性能和行为特征。根据输入数据和执行环境的不同，这些算法和策略可能会表现出不同的优势或劣势。
   由于这些因素的综合作用，程序在运行时可能会表现出截然不同的行为。因此，理解和分析这些行为对于优化程序性能、提高可靠性和稳定性至关重要。通过开发自动化的分析工具和方法，我们可以更深入地了解程序的行为特征，并据此设计出更有效的优化策略。

---

# 二、SimPoint是什么？

## 2.1 定义
首先，SimPoint是一款处理器芯片验证工具，它使用基于采样的模拟方法来识别程序中的热点代码段，并生成一个代表程序行为的子集，从而加速处理器模拟的速度。SimPoint能够大大缩短处理器验证的时间和成本，提高处理器设计的效率和可靠性。它特别适用于对大型和复杂程序进行模拟，以捕捉程序的主要性能特征。
## 2.2 ATOM 辅助工具
ATOM是一个程序分析和统计工具，它用于快速收集程序执行代码的相关剖析信息。在SimPoint的使用过程中，ATOM可以作为一个辅助工具，帮助研究人员获取程序的执行行为数据，这些数据是后续进行聚类分析和识别模拟点的基础。

## 2.3 SimpleScalar 验证工具
SimpleScalar是一个软件模拟工具，它能够模拟CPU、cache、memory等硬件架构。是一种较快的周期级模拟器，每小时大约能模拟 4 亿条指令。SimpleScalar在SimPoint的验证过程中发挥着重要作用，它用于验证通过SimPoint识别的模拟点是否能够准确反映程序的整体行为。具体来说，研究人员可以使用SimpleScalar在不同的硬件架构上运行这些模拟点，并比较性能指标，从而评估不同硬件架构对程序性能的影响。

# 三、基本块向量(BBV)
## 3.1 用途
简单来说，`基本块向量(BBV)`是一种技术，它允许我们分析出程序执行过程中的关键代码块（或“基本块”），并将这些代码块组合成一个`向量`，这个向量能够概括程序在特定时间间隔内的行为。之后，利用`聚类技术`（如K-means、层次聚类等）将这些向量分组，每个分组代表了一类相似的执行模式。通过这种方式，我们可以识别出程序中重复出现的行为模式，并为每个模式制定相应的优化策略。

## 3.2 相关定义
BBV是一个一维数组，数组中的每个元素对应于程序中一个静态基本块的计数，表示在执行的一个间隔内，**对应基本块被进入的次数乘以该基本块中的指令数**。通过乘以每个基本块中的指令数，我们可以确保无论指令位于大基本块还是小基本块中，都给予相同的权重。我们称通过计算在N×1000万条指令间隔内基本块执行次数而收集到的基本块向量为持续时间为N的基本块向量。

由于我们关注的不是给定间隔内基本块执行的实际次数，而是基本块中花费时间的比例，因此基本块向量会通过将每个元素除以向量中所有元素的总和来进行 `归一化处理`。这样，每个元素就代表了其对应基本块在执行间隔内所占总执行时间的比例。

归一化的基本块向量使得我们可以比较不同程序或不同执行阶段中基本块的相对重要性，而不需要考虑实际执行的指令总数。这种表示方法有助于识别程序中的热点区域，即那些在执行过程中占据大量时间的部分，从而为性能优化提供有价值的线索。

`优点`:这种方法的好处在于它是与硬件无关的，意味着它可以在不同的硬件平台上使用，并且不依赖于特定的硬件特性。这使得BBV成为一种非常有用的工具，可以帮助我们更深入地理解程序的行为，并发现潜在的优化机会。

## 3.3 计算方法：

 - 1.`欧几里得距离`
 - 2.`曼哈顿距离`

## 3.4 基本块相似矩阵
为了找出执行区间之间的关系，创建了一个基本块相似度矩阵。相似度矩阵是一个上三角形的 N × N 矩阵，其中 N 是程序执行中的区间数量。**矩阵中 (x, y) 位置的条目表示区间 x 和区间 y 之间基本块向量的曼哈顿距离**。

**相似度矩阵的作用**：通过相似度矩阵，我们能够可视化地展示程序执行过程中不同区间之间的相似度，帮助我们识别程序的不同阶段，并进一步分析程序在不同阶段的性能表现。

## 3.5 指标
我们通过几个不同的架构指标（如指令每条周期数（IPC）、分支预测失败率和缓存未命中率）来量化基本块向量在捕捉这些程序行为方面的有效性。
# 四、聚类
## 4.1 聚类背景
基本块向量提供了一个简洁且具有代表性的程序行为摘要，适用于执行的每个区间。通过检查它们之间的相似性，可以明显看出每个程序执行中存在高水平的模式。为了利用这些行为，我们需要首先定义一种方法来找到并表示这些信息。由于有很多执行区间彼此相似，一种有效的表示方式是将这些具有相似行为的区间分组在一起。这个问题类似于聚类问题。

## 4.2 聚类概述
聚类的目标是将一组点划分为多个组，使得每个组内的点彼此相似（按某种度量标准，通常是距离），而不同组的点彼此不同。这是一个活跃的研究领域。有许多聚类算法和不同的聚类方法。经典的聚类方法主要有两种：`划分式（Partitioning）`和`层次式（Hierarchical）`：

- 划分式算法：选择一个初始解，然后通过迭代更新来找到更好的解。像 k-means 和高斯期望最大化等流行算法属于这一类。这些算法通常具有与数据集大小成线性的运行时间。

- 层次式算法 ：这些算法通过两种方式聚集数据：一种是将相似点组合在一起（称为凝聚聚类，概念上类似于霍夫曼编码）；另一种是递归地将数据集划分为更多的组（称为分裂聚类）。这些算法的运行时间通常与数据集大小的平方成正比。
## 4.3 降维
对于这个聚类问题，我们需要解决维度问题。所有聚类算法都会遭遇所谓的“维度灾难”（curse of dimensionality），即随着维度数增加，数据的聚类变得非常困难。对于基本块向量来说，维度的数量就是程序中执行的基本块的数量，如果维度过大，算法会变得非常缓慢，所以需要降维：

- `维度选择`：通过根据每个维度对数据描述的优度来删除不必要的维度，但这样会丢弃很多信息
- `维度减少`：通过创建一个新的低维空间，并将每个数据点投影到该新空间来减少维度
## 4.4 举例（维度减少）
通过以下两个步骤，可以将数据集 X（一个基本块向量的矩阵，大小为 Nintervals × Dnumbb，其中 Dnumbb 是程序中的基本块数量）降到 Dnew 维度(会有一定误差，但影响不大)：

- 创建一个 Dnumbb × Dnew 的投影矩阵 M，每个矩阵项的值在 -1 和 1 之间随机选择。
- 将 X 与 M 相乘，得到新的低维数据集 X′，其大小为 Nintervals × Dnew。

## 4.5 K-means算法
 **算法初始化**：
随机选择 k 个聚类中心：首先，算法随机选择 k 个数据点作为初始的聚类中心。这些中心点是算法开始时的初始猜测。

**算法的两个阶段（重复执行直到收敛）**：
 -  阶段 1：分配数据点到聚类中心
   对于每个数据点，计算它到每个聚类中心的距离（常用欧氏距离），并将它分配到最近的聚类中心。即每个数据点根据距离最小的原则，成为某个聚类的成员。
 - 阶段 2：更新聚类中心的位置
   对于每个聚类中心，计算它所在聚类中所有点的“质心”，即该聚类中所有数据点的均值。这些均值会作为新的聚类中心位置。质心是反映该聚类数据点整体分布的中心点。

## 4.6 贝叶斯信息准则（BIC）
为了比较和评估不同 k 值下形成的聚类，使用贝叶斯信息准则（BIC） 来衡量聚类对数据集的拟合优度。更正式地说，BIC 是对给定数据集的聚类概率的近似。因此，**BIC 分数越大，表示该聚类方案与数据的拟合度越高**。

### 选择最优的k
对于给定的程序和输入，BIC 分数会计算每个 k-均值聚类，k 从 1 到N。然后我们选择达到 BIC 分数的聚类，该分数至少占该算法观察到的**最大和最小 BIC 分数之间差值的 90%**。

### IPC方差
`IPC 方差`是通过对每个聚类的 IPC 方差进行加权求和计算的，其中聚类的权重是该聚类中点的数量。每个聚类的 IPC 方差简单地是该聚类内所有点的 IPC 方差。IPC方差是衡量程序执行效率波动的指标。**IPC 方差越大，说明程序执行时每个周期的效率波动越大**，可能存在性能不稳定的情况。

# 五、选择模拟点
## 5.1 定义
模拟点代表了程序执行中的一个子集，目的是通过模拟这个子集来近似整个程序的执行过程。

## 5.2 选择算法
### 质心（Centroid）法：

质心是聚类中所有点（BBV）在每个维度上的平均值。简单来说，质心是聚类内所有数据点的 几何中心，它代表了该簇的“中心”位置。
在聚类后，选择每个簇的 质心 作为该簇的 模拟点。质心本质上是通过计算聚类内所有点的平均值来形成的，因此它能够较好地代表该聚类的整体行为。

步骤：
- 对于每个聚类，计算聚类内所有 BBV 的均值，得到该簇的 质心。
- 将质心作为该聚类的 模拟点，用来代表该聚类的执行行为。


**优点**：简单、直接，能够迅速生成聚类中心的模拟点。
**缺点**：不考虑簇内数据点的实际分布，因此生成的模拟点可能会偏离簇内实际分布，特别是当簇形状不规则时。


### 质心法特点：
质心是聚类中所有点的平均表现，它能代表该簇内所有程序区间的“典型行为”。由于聚类的目的是将具有相似行为的程序区间分为同一簇，因此簇的质心通常能够较好地表示该簇内所有点的整体特征。

质心法是一个 全局视角，选择质心作为模拟点时，它能够捕捉到整个簇内的平均行为，避免过度依赖个别极端的程序区间。
### 最小距离法：

最小距离法 是通过计算聚类内每个 BBV 与聚类质心之间的距离（例如欧几里得距离或曼哈顿距离），然后选择 距离质心最小的 BBV 作为模拟点。这个方法本质上是选择最接近聚类中心的一个数据点来代表该聚类。

步骤：

- 对于每个聚类，计算每个 BBV 与该簇的 质心 的距离。
- 选择距离质心最近的 BBV 作为该聚类的 模拟点。

**优点**：通过最小化与质心的距离，保证生成的模拟点更加代表性，覆盖簇的不同区域。
**缺点**：相较于质心法，可能需要更多的计算资源，尤其在簇内数据分布较复杂时。
### 最小距离法特点：
有时，聚类的质心可能**由于簇内数据分布的不均匀而偏离某些具有代表性的执行区间，特别是当簇内的点表现出较大差异**时。最小距离法通过选择最接近质心的点，能够确保选出的模拟点是簇内最典型的、最能代表该簇行为的区间。

这种方法可以在簇内数据分布较广的情况下，更准确地选择代表性模拟点。


### 基于分布（如高斯分布）的采样方法
这些方法通过统计聚类簇内的样本分布特征（如均值、方差或协方差矩阵），然后从该分布中采样新的数据点。这种方法能够生成更符合簇内真实数据特征的模拟点，尤其适用于簇形状较为复杂或数据有较大内部变化的情况。如高斯分布采样、多元分布采样等

## 5.3 单一模拟点：
单一模拟点的结果与程序的完整执行结果非常接近，尤其是与一些临时性的方法相比。直接从程序开始进行模拟的平均误差为210%，而盲目快进则导致80%的IPC误差。通过使用我们的单一模拟点分析方法，平均IPC误差降到了18%。这些结果表明，使用一个非常小的执行片段来捕捉大多数程序的行为是可行的。

**缺陷**：
单一的模拟点对于许多程序是准确的，但对于像bzip、gzip和gcc这样的程序仍然存在显著的误差。这是因为这些程序有许多不同的执行阶段，单一模拟点无法准确代表所有不同的执行阶段。为了解决这个问题，我们使用了聚类分析来找到多个模拟点，以准确捕捉这些程序的行为


## 5.4 多个模拟点：
为了支持多个模拟点，模拟器可以从头到尾运行，只对选定的间隔进行详细模拟。或者，模拟可以分解为 N 个独立的模拟，每个模拟对应通过分析找到的一个集群，每个模拟单独运行。这种方法还有一个额外的好处，即将模拟分解为多个并行组件，可以在多个处理器上分布执行。在这两种情况下，来自各个模拟点的结果需要加权并组合，以得出程序的总体性能。

**选择代表性点：**单纯的集群分析（即分析不同执行阶段的分布）不足以直接进行多个模拟点的选择，因为集群的“中心”（即质心）并不一定与程序中的实际执行间隔一致。为了解决这个问题，选择每个集群中与其中心最接近的实际执行间隔作为代表点。这样可以确保每个集群都能被准确地近似。

**加权代表点：**每个集群的代表性点的影响力是根据该集群的大小来加权的。如果一个集群只有一个模拟点，它对最终结果的影响会较小，因为它只代表程序执行的一个小部分。相反，如果一个集群包含多个模拟点，则该集群的代表点将对结果产生更大的影响。
# 六、相关应用
## SPEC 2006
是由标准性能评价组织（SPEC）开发的一套用于评测CPU性能的基准程序测试组。该测试组包括了一系列经过精心设计的程序，旨在全面评估CPU的整数和浮点运算能力。这些程序都是从实际应用程序中提取出来的，具有真实性和通用性，因此被广泛用于计算机体系结构研究和性能评估中。

而SimPoint则是一款流行的处理器芯片验证工具，它使用基于采样的模拟方法来识别程序中的热点代码段，并生成一个代表程序行为的子集，从而加速处理器模拟的速度。SimPoint能够大大缩短处理器验证的时间和成本，提高处理器设计的效率和可靠性。它特别适用于对大型和复杂程序进行模拟，如SPEC 2006中的基准程序。

## 2. SPEC 2006特点
SPEC CPU 2006测试的主要目标是评估CPU的性能，特别是处理器在处理整数和浮点运算方面的能力。因此，测试的设计重点放在了能够充分反映CPU性能的关键组件上，即处理器、内存子系统和编译器。这些组件是CPU性能评估中的核心要素，它们的性能表现直接影响到CPU的整体性能。
其次，I/O（磁盘）、网络、操作系统和图形子系统虽然也是计算机系统的重要组成部分，但在SPEC CPU 2006测试中，它们对CPU性能评估的影响相对较小。这是因为这些组件的性能更多地与数据传输、网络通信、系统管理和图形渲染等方面相关，而不是直接反映CPU的计算能力。因此，在SPEC CPU 2006测试中，这些组件的影响被最小化，以确保测试的准确性和针对性。

---


